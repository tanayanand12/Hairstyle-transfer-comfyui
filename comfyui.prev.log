** ComfyUI startup time: 2024-04-18 09:40:50.651842
[2024-04-18 09:40] ** Platform: Windows
[2024-04-18 09:40] ** Python version: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
[2024-04-18 09:40] ** Python executable: D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\python_embeded\python.exe
[2024-04-18 09:40] ** Log path: D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\comfyui.log
[2024-04-18 09:40] 
Prestartup times for custom nodes:
[2024-04-18 09:40]    0.6 seconds: D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\ComfyUI\custom_nodes\ComfyUI-Manager
[2024-04-18 09:40] 
Total VRAM 4096 MB, total RAM 32125 MB
[2024-04-18 09:40] Trying to enable lowvram mode because your GPU seems to have 4GB or less. If you don't want this use: --normalvram
[2024-04-18 09:40] Set vram state to: LOW_VRAM
[2024-04-18 09:40] Device: cuda:0 NVIDIA GeForce GTX 1650 : native
[2024-04-18 09:40] VAE dtype: torch.float32
[2024-04-18 09:40] Using pytorch cross attention
[2024-04-18 09:41] ### Loading: ComfyUI-Manager (V2.16.1)
[2024-04-18 09:41] ### ComfyUI Revision: 2119 [30abc324] | Released on '2024-04-08'
[2024-04-18 09:41] 
Import times for custom nodes:
[2024-04-18 09:41]    0.0 seconds: D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\ComfyUI\custom_nodes\websocket_image_save.py
[2024-04-18 09:41]    0.0 seconds: D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\ComfyUI\custom_nodes\efficiency-nodes-comfyui
[2024-04-18 09:41]    0.0 seconds: D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\ComfyUI\custom_nodes\Derfuu_ComfyUI_ModdedNodes
[2024-04-18 09:41]    0.5 seconds: D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\ComfyUI\custom_nodes\ComfyUI-Manager
[2024-04-18 09:41] 
[2024-04-18 09:41] Starting server

[2024-04-18 09:41] To see the GUI go to: http://127.0.0.1:8188
[2024-04-18 09:41] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[2024-04-18 09:41] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-04-18 09:41] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-18 09:41] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[2024-04-18 09:41] FETCH DATA from: D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\ComfyUI\custom_nodes\ComfyUI-Manager\extension-node-map.json
[2024-04-18 09:44] got prompt
[2024-04-18 09:44] model_type EPS
[2024-04-18 09:44] Using pytorch attention in VAE
[2024-04-18 09:44] Using pytorch attention in VAE
[2024-04-18 09:44] clip missing: ['clip_l.logit_scale', 'clip_l.transformer.text_projection.weight']
[2024-04-18 09:44] Requested to load SD1ClipModel
[2024-04-18 09:44] Loading 1 new model
[2024-04-18 09:44] Requested to load AutoencoderKL
[2024-04-18 09:44] Loading 1 new model
[2024-04-18 09:44] D:\learning\python learner\keshcutai\ComfyUI__main\ComfyUI_windows_portable\ComfyUI\comfy\ldm\modules\diffusionmodules\model.py:236: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  out = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0.0, is_causal=False)
[2024-04-18 09:44] Requested to load BaseModel
[2024-04-18 09:44] Loading 1 new model
[2024-04-18 09:45] 100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.53s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.52s/it]
[2024-04-18 09:45] Requested to load AutoencoderKL
[2024-04-18 09:45] Loading 1 new model
[2024-04-18 09:45] Requested to load BaseModel
[2024-04-18 09:45] Loading 1 new model
[2024-04-18 09:46] 100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.54s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.54s/it]
[2024-04-18 09:46] Requested to load AutoencoderKL
[2024-04-18 09:46] Loading 1 new model
[2024-04-18 09:46] Prompt executed in 97.08 seconds
[2024-04-18 09:46] got prompt
[2024-04-18 09:46] Requested to load BaseModel
[2024-04-18 09:46] Loading 1 new model
[2024-04-18 09:47] 100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.54s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.54s/it]
[2024-04-18 09:47] Requested to load AutoencoderKL
[2024-04-18 09:47] Loading 1 new model
[2024-04-18 09:47] Requested to load BaseModel
[2024-04-18 09:47] Loading 1 new model
[2024-04-18 09:48] 100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.55s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.55s/it]
[2024-04-18 09:48] Requested to load AutoencoderKL
[2024-04-18 09:48] Loading 1 new model
[2024-04-18 09:48] Prompt executed in 90.25 seconds
[2024-04-18 09:49] got prompt
[2024-04-18 09:49] Requested to load BaseModel
[2024-04-18 09:49] Loading 1 new model
[2024-04-18 09:49] 100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.54s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.53s/it]
[2024-04-18 09:49] Requested to load AutoencoderKL
[2024-04-18 09:49] Loading 1 new model
[2024-04-18 09:49] Requested to load BaseModel
[2024-04-18 09:49] Loading 1 new model
[2024-04-18 09:50] 100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.55s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.55s/it]
[2024-04-18 09:50] Requested to load AutoencoderKL
[2024-04-18 09:50] Loading 1 new model
[2024-04-18 09:50] Prompt executed in 90.27 seconds
[2024-04-18 09:53] got prompt
[2024-04-18 09:53] Requested to load BaseModel
[2024-04-18 09:53] Loading 1 new model
[2024-04-18 09:53] 100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.53s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.53s/it]
[2024-04-18 09:53] Requested to load AutoencoderKL
[2024-04-18 09:53] Loading 1 new model
[2024-04-18 09:53] Requested to load BaseModel
[2024-04-18 09:53] Loading 1 new model
[2024-04-18 09:54] 100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.55s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.55s/it]
[2024-04-18 09:54] Requested to load AutoencoderKL
[2024-04-18 09:54] Loading 1 new model
[2024-04-18 09:54] Prompt executed in 91.41 seconds
[2024-04-18 10:09] got prompt
[2024-04-18 10:09] Requested to load BaseModel
[2024-04-18 10:09] Loading 1 new model
[2024-04-18 10:10] 100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:08<00:00,  2.75s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:08<00:00,  2.75s/it]
[2024-04-18 10:10] Requested to load AutoencoderKL
[2024-04-18 10:10] Loading 1 new model
[2024-04-18 10:10] Requested to load BaseModel
[2024-04-18 10:10] Loading 1 new model
[2024-04-18 10:12] 100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:21<00:00,  2.79s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:21<00:00,  2.71s/it]
[2024-04-18 10:12] Requested to load AutoencoderKL
[2024-04-18 10:12] Loading 1 new model
[2024-04-18 10:12] Prompt executed in 157.24 seconds
[2024-04-18 10:26] got prompt
[2024-04-18 10:26] Requested to load BaseModel
[2024-04-18 10:26] Loading 1 new model
[2024-04-18 10:28] 100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:46<00:00,  2.75s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:46<00:00,  2.66s/it]
[2024-04-18 10:28] Requested to load AutoencoderKL
[2024-04-18 10:28] Loading 1 new model
[2024-04-18 10:28] Requested to load BaseModel
[2024-04-18 10:28] Loading 1 new model
[2024-04-18 10:30] 100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [02:17<00:00,  2.75s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [02:17<00:00,  2.75s/it]
[2024-04-18 10:30] Requested to load AutoencoderKL
[2024-04-18 10:30] Loading 1 new model
[2024-04-18 10:30] Prompt executed in 252.56 seconds
[2024-04-18 10:43] got prompt
[2024-04-18 10:43] Requested to load BaseModel
[2024-04-18 10:43] Loading 1 new model
[2024-04-18 10:44] 100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:01<00:00,  1.55s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:01<00:00,  1.54s/it]
[2024-04-18 10:44] Requested to load AutoencoderKL
[2024-04-18 10:44] Loading 1 new model
[2024-04-18 10:44] Requested to load BaseModel
[2024-04-18 10:44] Loading 1 new model
[2024-04-18 10:45] 100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [01:17<00:00,  1.56s/it]100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [01:17<00:00,  1.55s/it]
[2024-04-18 10:45] Requested to load AutoencoderKL
[2024-04-18 10:45] Loading 1 new model
[2024-04-18 10:45] Prompt executed in 145.82 seconds
[2024-04-18 10:51] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-04-18 10:51] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-18 10:51] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-18 10:53] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-04-18 10:53] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-18 10:53] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[2024-04-18 10:53] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-04-18 10:53] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-18 10:55] got prompt
[2024-04-18 10:55] Prompt executed in 0.13 seconds
[2024-04-18 10:56] got prompt
[2024-04-18 10:56] Prompt executed in 0.00 seconds
[2024-04-18 10:56] got prompt
[2024-04-18 10:56] Prompt executed in 0.00 seconds
[2024-04-18 10:56] got prompt
[2024-04-18 10:56] Prompt executed in 0.00 seconds
[2024-04-18 10:56] got prompt
[2024-04-18 10:56] Prompt executed in 0.00 seconds
[2024-04-18 10:56] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-04-18 10:56] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-18 10:56] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-18 10:58] got prompt
[2024-04-18 10:58] Prompt executed in 0.00 seconds
[2024-04-18 10:58] got prompt
[2024-04-18 10:58] Prompt executed in 0.00 seconds
[2024-04-18 10:59] got prompt
[2024-04-18 10:59] Prompt executed in 0.11 seconds
[2024-04-18 10:59] got prompt
[2024-04-18 10:59] Prompt executed in 0.00 seconds
[2024-04-18 10:59] got prompt
[2024-04-18 10:59] Prompt executed in 0.00 seconds
[2024-04-18 10:59] got prompt
[2024-04-18 10:59] Prompt executed in 0.00 seconds
[2024-04-18 10:59] got prompt
[2024-04-18 10:59] Prompt executed in 0.00 seconds
[2024-04-18 10:59] got prompt
[2024-04-18 10:59] Prompt executed in 0.00 seconds
[2024-04-18 11:00] 
Stopped server
